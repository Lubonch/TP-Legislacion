\section*{CONCLUSIÓN}
\addcontentsline{toc}{section}{CONCLUSIÓN}

El avance constante de la tecnología transformó la forma en la que interactuamos y nos comunicamos entre nosotros. Estos cambios trajeron consigo nuevos desafíos y riesgos, sobre todo cuando se trata de proteger a los menores de edad. Esto genera la necesidad de establecer marcos regulatorios que los protejan pero que a su vez no limiten su libertad de expresión y acceso a la información.

La regulación internacional muestra que no existe una solución única, mientras en la Unión Europea se optó por un enfoque que mezcla la regulación de datos y la transparencia de los algoritmos, en Australia se tomó una medida más drástica prohibiendo el acceso a las redes sociales para los menores de 16 años. Un gran desafío que tienen estas regulaciones es encontrar el equilibrio en la protección de los derechos de primera generación y la cuarta generación, ya que la protección de los datos busca prevenir que la dignidad humana se vea afectada por el manejo indiscriminado de datos personales.

El caso de Discord muestra cómo la implementación de un sistema de verificación de edad puede generar riesgos críticos en la seguridad de los datos y que si bien la verificación de edad es importante para proteger a los menores, el no garantizar que los datos sensibles sean eliminados adecuadamente puede exponer a todos los usuarios a problemas más graves.

En Argentina, el marco jurídico actual nos da una base sólida que requiere actualización para poder abordar estos problemas. La Ley de Protección de Datos Personales (25.326) ya establece el principio de calidad de los datos y obliga a que la recolección sea adecuada y no excesiva, y que estos datos sean destruidos una vez que se cumpliera la finalidad para la que fue recolectado. Sin embargo, esta ley debería incluir una disposición específica sobre los algoritmos y la verificación de edad para controlar las decisiones automatizadas que pueden poner en peligro la dignidad de la persona.