\section{EL SISTEMA DE DERECHOS}

El ordenamiento jurídico argentino establece una jerarquía normativa, colocando en lo más alto a la constitución nacional junto con los tratados internacionales incorporados mediante el Art. 72 inc. 22

Esta estructura constitucional reconoce la evolución histórica de los derechos fundamentales, los cuales se pueden categorizar en distintas generaciones según su desarrollo temporal y características.

\begin{enumerate}
    \item \textbf{Derechos de Primera Generación :} Surge durante las grandes revoluciones liberales(como la Revolución Francesa), con el propósito de establecer un límite entre el poder del estado y la autonomía individual. Incluye la libertad de expresión y el derecho a la intimidad.
    \item \textbf{Derechos de Segunda Generación :} Corresponden a los Derechos Económicos Sociales y Culturales que surgieron a principios del siglo XX en respuesta a las desigualdades y explotación laboral derivadas de la revolución industrial
    \item \textbf{Derechos de Tercera Generación :} Corresponden a los derechos colectivos, responden a la necesidad de proteger intereses compartidos, como el derecho a un medio ambiente sano, los derechos de los pueblos originarios. Sin estos derechos se pondría en riesgo el ejercicio de las generaciones anteriores.
    \item \textbf{Derechos de Cuarta Generación :} Corresponden a los derechos que nacen del mundo informático, busca adaptar las garantías fundamentales al entorno digital. Incluyen el derecho al libre acceso a la información, la reducción de la brecha digital y la protección de datos personales.
\end{enumerate}   

\section{RIESGOS DIGITALES Y DELITOS INFORMÁTICOS CONTRA MENORES}

La exposición de los menores de edad a los riesgos del entorno digital requieren la intervención del derecho penal y civil. En Argentina, el Código civil y comercial de la nación establece el régimen de capacidad progresiva, que afecta cómo el menor ejerce sus derechos.

\textbf{Capacidad progresiva :} Una persona menor de 13 años no es capaz de ejercer derechos por sí misma y requiere la representación de sus padres o tutores legales. Los adolescentes entre 13 y 16 años tienen una capacidad limitada y son escuchados en procesos que los involucran. A partir de los 16 años ya es considerado un adulto para las decisiones relacionadas con el cuidado de su cuerpo.

\subsection{Delitos y contenidos ilícitos}

\begin{enumerate}
    \item \textbf{Pornografía Infantil :} La Ley 26.388 tipifica la pornografía infantil(art 128 Código Penal) como la representación de un menor de dieciocho años dedicado a actividades sexuales explícitas.
    \item \textbf{Grooming :} La Ley 26.904 tipifica el grooming como el acto de un adulto que contacta a un menor de edad mediante medios digitales con el propósito de cometer un delito contra su integridad sexual.
    \item \textbf{Acceso ilegal a datos personales :} El acceso ilegal(Art. 153 bis y 157 bis del Código Penal) es tipificado por la Ley 26.388. Incluye la violación de correos electrónicos, redes sociales y otros servicios digitales. 
\end{enumerate}

\section{Regulación internacional}

\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{|p{3.5cm}|p{2.5cm}|p{8cm}|}
\hline
\textbf{País/Ley} & \textbf{Edad Mínima} & \textbf{Características principales} \\
\hline
\textbf{Estados Unidos} \newline KOSMA/PKSMA (S.278) & 13 años (cuentas) \newline 17 años (algoritmos) & Prohíbe los sistemas de recomendación personalizados (profiling) para menores de 17 años. Pendiente de promulgación (Entraría en vigor 1 año después de su aprobación). \\
\hline
\textbf{Australia} \newline Online Safety Act & 16 años & Prohíbe el acceso a redes sociales a menores de 16 años. Requiere verificación de edad a los titulares de cuentas en las plataformas restringidas. Vigente: 10 de Diciembre 2025. \\
\hline
\textbf{Unión Europea} \newline Digital Services Act & 13 años (Aprobación PE) \newline Debate: 15/16 años & Exige a las grandes plataformas online (VLOPs) que eliminen mecanismos adictivos. Busca implementar la "Cartera Digital" euro{p}ea para control de edad más efectivo. Vigente: 16 de Noviembre 2022. \\
\hline
\end{tabular}
\caption{Comparación de regulaciones internacionales sobre protección de menores en redes sociales}
\end{table}

\begin{enumerate}
    \item \textbf{PKSMA/KOSMA :} El proyecto S. 278 busca prohibir que los menores de 13 años accedan a redes sociales y limitar los sistemas de recomendación personalizados(profiling) para menores de 17 años. 
    \item \textbf{OSA :} La OSA(online safety act) prohíbe el acceso a redes sociales a menores de 16 años, exige que las plataformas implementen medidas para el cumplimiento e impone multas millonarias por la violación. Exige la verificación de edad para todos los titulares de cuentas en plataformas que estén restringidas por edad.
    \item \textbf{DSA :}  La DSA(Digital Service Act) obliga a las grandes plataformas a tener la responsabilidad de proteger a los menores. Prohíbe la eliminación de mecanismos adictivos(como las "rachas" o "streaks") y exige verificación de edad para acceder a servicios en línea.
    El Parlamento Europeo aprobó fijar la edad mínima de acceso a redes sociales en 13 años, pero los estados miembros debaten elevarla a los 15 o 16 años.
    La comisión europea está trabajando en el desarrollo de la "European digital wallet" para facilitar la verificación de la identidad digital y facilitar la implementación de controles de edad.
\end{enumerate}

\section{El impacto de la regulación de redes en el sistema de derechos}

La regulación de las redes sociales impone deberes de control que generan un impacto directo en las distintas generaciones de derechos.

\begin{enumerate}
    \item \textbf{Libertad de expresión y la primera Generación :} Los filtros y controles de contenido pueden crear efectos de censura que limitan la libertad de expresión. Existe el riesgo de que algoritmos de detección eliminen contenido legítimo o que la autocensura se incremente por temores a las restricciones. Esto plantea un dilema entre proteger a los menores sin vulnerar los principios que caracterizan a los derechos de primera generación.

    \item \textbf{Refuerzo de la tercera y cuarta generación:} La regulación internacional se justifica ya que los usuarios no tienen el mismo nivel de conocimiento técnico que tienen las plataformas digitales. Por lo que la regulación busca proteger los derechos colectivos.

    \begin{itemize}
        \item \textbf{Libertad de expresión:} El control algorítmico y el profiling se basan en almacenar los datos de forma indiscriminada, lo que genera un oligopolio de la información y pone en riesgo la autodeterminación informativa de los usuarios. Al exigir que las grandes plataformas eliminen los mecanismos adictivos y prohibir el profiling para menores, se refuerza el control del individuo sobre sus datos personales.
        
        \item \textbf{Protección de datos y verificación de edad:} Implementar sistemas de verificación de edad por parte de las plataformas conlleva grandes riesgos de privacidad. La recolección de datos sensibles necesarios para esta verificación genera una gran incertidumbre sobre cómo se van a proteger estos datos. Esto aplica tanto a menores como a los adultos, ya que ambos pueden verse afectados por la mala gestión de estos datos.
    \end{itemize}
\end{enumerate}

\subsection{Verificación de edad y sus riesgos: El caso de Discord}

Discord es una aplicación de mensajería que permite a los usuarios crear servidores y canales para comunicarse a través de texto, voz y video. 

Durante abril del 2025 Discord comenzó a implementar un sistema de verificación de edad solicitando una foto de un documento de identidad para adelantarse a las futuras regulaciones, prometiendo que las fotos solo se iban a usar para la verificación y que no iban a ser almacenadas.

Sin embargo, en octubre del 2025 un incidente de seguridad que sufrió un proveedor externo de servicios (5SA) puso en compromiso los datos personales de unos 70.000 usuarios, incluyendo las fotos de los documentos de identidad que se usaron para verificación de edad.

Este caso pone en evidencia que más allá de proteger a los menores de edad, la verificación de edad trae nuevos riesgos que se deben considerar al momento de implementar estos sistemas y se debe tener un marco de seguridad legal que imponga:
\begin{itemize}
        \item La obligación de garantizar que las plataformas adopten medidas de seguridad y confidencialidad para proteger los datos personales sensibles.
        \item La supresion de datos sensisbles una vez que  se haya completado la funcional para la que fueron recolectados.
        \item Delegar los procesos de verificación a proveedores externos no debe sacar la responsabilidad de proteger los datos personales a las plataformas digitales. 
\end{itemize}

\section{¿Cómo aborda la justicia Argentina la regulación de redes sociales?}

La justicia argentina aborda los conflictos del entorno digital aplicando los principios generales del derecho adaptándolos a un contexto tecnológico.

\subsection{Responsabilidad de los proveedores de servicios}

Los proveedores de servicios de internet son definidos como intermediarios tecnológicos que permiten acceder a redes datos, así como también transmitir y almacenar los datos.

La ley 27.078(Ley argentina Digital) declara de interés público el desarrollo de las TICs y establece principios para los prestadores de servicios:

\begin{enumerate}
    \item \textbf{Neutralidad de Red :} Garantiza la completa neutralidad de las redes y prohíbe que los prestadores de servicios bloqueen, interfieran o restrinjan el acceso a cualquier contenido o aplicación, salvo por una orden judicial o una expresa solicitud del usuario.

    \item \textbf{Inviolabilidad de las comunicaciones :} Garantiza la inviolabilidad de la correspondencia y comunicaciones electrónicas, incluyendo los datos de tráfico. Su intercepción solo puede realizarse mediante una orden judicial.
\end{enumerate}

Los proveedores de servicio también tienen el deber de prevenir el daño que tiene cualquier otra persona (Art 1710 CCyC), lo que les exige tener que adoptar medidas necesarias para evitar que se produzca un daño o en el peor de los casos disminuir su magnitud. Esto se ve reforzado por las obligaciones legales específicas:

\begin{enumerate}
    \item \textbf{La obligación de ofrecer software de protección que impida el acceso a sitios específicos}, al momento de ofrecer los servicios de internet (ley 25.690).

    \item \textbf{La obligación de informar y recomendar el uso de programas de bloqueo de sitios}, en las facturas que emiten. Esta inscripción debe recomendar a los padres a "ejercer un razonable control por los contenidos que consumen sus hijos" y aconsejar que consulten con el proveedor para que les brinde asesoramiento sobre programas de bloqueo de sitios.  
\end{enumerate}

\subsection{Responsabilidad parental y el sharenting}

La Responsabilidad parental es el conjunto de deberes y derechos que tienen los padres sobre la persona y bienes del hijo para su protección, desarrollo y formación integral(y dentro del contexto digital también incluye la protección de su identidad digital y privacidad). El estado actúa como garante para exigir el cumplimiento de estos deberes.

La ley 26.061 establece que los menores tienen el derecho a ser respetados en su dignidad, reputación y propia imagen.

El sharenting es la práctica de los padres donde comparten contenido relacionado con sus hijos en las redes sociales y ha generado jurisprudencia debido a la ausencia de legislación donde los tribunales intervinieron para proteger los derechos personalísimos de los hijos.

\begin{enumerate}
    \item \textbf{V. F. C/ S. B. S/ MEDIDAS PRECAUTORIAS (ART. 232 DEL CPCC) :} en el fallo el Padre(V. F. C.) solicita que se intime a la madre(S. B.) a abstenerse de subir fotos y videos de sus hijas en redes sociales con fines comerciales.
    El tribunal aplicó el interés superior del niño, dándole prioridad a los derechos personalísimos de las niñas sobre el derecho a la libertad de expresión de la madre.

    El Fallo reafirma que la responsabilidad parental no incluye el derecho a exponer a los hijos en las redes sociales y no puede realizarse de forma unilateral y siempre debe ceder ante el interés y la voluntad del niño.
\end{enumerate}